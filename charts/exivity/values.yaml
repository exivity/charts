# -- Override deployment name (e.g., useful when deploying multiple instances of the application).
nameOverride: ""

# Set to the actual licence for production environments.
# For evaluation purposes, use "demo", but note that "demo" will not allow you to run reports.
# For a trial license, please contact license@exivity.com.
licence: "demo"

# Secret keys used for application security. Random values are generated on installation if not set.
# Random values are generated on installation if not set, but it's recommended to specify values for production.
secret:
  appKey: "" # Used to encrypt application data. Specify a value for production.
  jwtSecret: "" # Used for signing JWTs. Specify a value for production.

ingress:
  enabled: true # Indicates if ingress is enabled.
  host: exivity # The host or domain name for the ingress route.
  ingressClassName: "" # Ingress class name; if empty, no class is set.

  # Trusted proxies are configured for handling headers correctly behind a proxy or load balancer.
  # This is used particularly when services like Traefik act as the load balancer in a Kubernetes cluster.
  # Specify IP addresses, CIDR blocks, or a wildcard '*' to trust all proxies.
  # Example values: '10.0.0.1', '10.244.0.0/16', '127.0.0.1, 10.244.0.0/16', or '*'.
  trustedProxy: ""

  annotations:
    {}
    # Example annotations for ingress behavior:
    # kubernetes.io/ingress.allow-http:         "false"
    # nginx.ingress.kubernetes.io/ssl-redirect: "true"
    # nginx.ingress.kubernetes.io/use-regex:    "true"

  tls:
    enabled: false # Controls if TLS is handled by ingress; disable if TLS is terminated externally.
    secret: "-" # Name of an existing TLS secret or '-' to generate a new certificate.

storage:
  storageClass: "" # Specifies the storage class used for provisioning volumes. If empty, the default class is used.
  helmResourcePolicyKeep: true # Ensures that storage resources are retained after a Helm release is deleted.
  sharedVolumeAccessMode: ReadWriteMany # Defines the access mode for shared volumes; 'ReadWriteMany' allows multiple nodes to read/write simultaneously.

# Configuration for PostgreSQL, either as an embedded database using the Bitnami PostgreSQL chart or an external database.
# It is recommended to use an external PostgreSQL server for production environments to ensure scalability and manageability.
# The embedded PostgreSQL chart is primarily intended for testing and non-production purposes.
postgresql:
  enabled: true # Determines if the Bitnami PostgreSQL chart should be installed. Set to false when using an external database.
  global:
    postgresql:
      auth:
        database: exivity # Database name for both external and embedded databases.
        username: exivity # Username for accessing the database.
        password: Password12! # Password for the database user.
        postgresPassword: Password13! # Root password for PostgreSQL, optional when using an external database.

  # Configuration for using an external PostgreSQL database.
  host: "" # Hostname of the external database server, if applicable.
  port: "" # Port number on which the external database server is accessible.
  sslmode: "" # SSL mode for database connection: 'disable', 'require', 'verify-ca', or 'verify-full'.

  # Example of customizing the embedded Bitnami PostgreSQL chart for larger deployments.
  # For more options and details, refer to the Bitnami PostgreSQL Helm chart: https://bitnami.com/stack/postgresql/helm
  # primary:
  #   persistence:
  #     size: 50Gi  # Specifies the size of the persistent volume.
  #   extendedConfiguration: |
  #     shared_buffers = 2GB  # Sets the amount of memory the database server uses for shared buffers.
  #     work_mem = 32MB  # Sets the amount of memory used by internal sort operations and hash tables.
  #     wal_buffers = 64MB  # Sets the amount of memory used by WAL buffers.

# Configuration for RabbitMQ, either as an embedded server using the Bitnami RabbitMQ chart or an external message queue.
# It is recommended to use an external RabbitMQ server for production environments to ensure scalability and manageability.
# The embedded RabbitMQ chart is primarily intended for testing and non-production purposes.
# For more options and details, refer to the Bitnami RabbitMQ Helm chart: https://bitnami.com/stack/rabbitmq/helm
rabbitmq:
  enabled: true # Determines if the Bitnami RabbitMQ chart should be installed. Set to false when using an external MQ.
  clustering:
    enabled: false # Determines if clustering is enabled for RabbitMQ.

  auth:
    username: user # Username for RabbitMQ authentication.
    password: pass # Password for RabbitMQ authentication.

  # Configuration for using an external RabbitMQ server.
  host: "" # Hostname of the external RabbitMQ server, if applicable.
  port: "" # Port number on which the external RabbitMQ server is accessible.
  vhost: "" # Virtual host for RabbitMQ, if applicable.
  secure: "" # Indicates if the connection to RabbitMQ should be secured (true/false). Set to true to enable TLS for RabbitMQ communication.

# General service configuration, defaults apply when specific service settings are not provided.
service:
  registry: docker.io # Default registry from which to pull service images.
  tag: "" # Docker image tag; specify to use a specific version.
  pullPolicy: IfNotPresent # Image pull policy; 'IfNotPresent' only pulls if the image isn't already present.

  # List of image pull secrets, used if private Docker registries require authentication.
  pullSecrets: [] # Example: ["myRegistryKey"] - Use the Kubernetes Secret name that contains the Docker registry credentials.

  # Example of an image pull secret in YAML configuration:
  # This configuration is typically applied using a Kubernetes Secret resource.
  # Here is a simple example of how an image pull secret might be defined:
  #
  # apiVersion: v1
  # kind: Secret
  # metadata:
  #   name: myRegistryKey
  # type: kubernetes.io/dockerconfigjson
  # data:
  #   .dockerconfigjson: <base64-encoded-docker-config-json>
  #
  # Replace <base64-encoded-docker-config-json> with the base64-encoded JSON string that contains the registry authentication information.

  # Configuration for the 'glass' service, Exivity's front-end component.
  glass:
    registry: ""
    repository: exivity/glass
    tag: ""
    pullPolicy: ""
    servicePort: 80
    serviceType: ClusterIP
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'proximityApi' service, handling backend API operations.
  proximityApi:
    registry: ""
    repository: exivity/proximity-api
    tag: ""
    pullPolicy: ""
    # set the PHP memory limit per requests
    # https://www.php.net/manual/en/ini.core.php#ini.memory-limit
    phpMemoryLimit: "3G"
    servicePort: 80
    serviceType: ClusterIP
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "400Mi"

  # Configuration for the 'chronos' service, part of the back-end components.
  chronos:
    registry: ""
    repository: exivity/chronos
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'dbInit' service, which initializes the database.
  dbInit:
    registry: ""
    repository: exivity/db
    tag: ""
    pullPolicy: ""
    nodeName: ""
    nodeSelector: {}
    # Configuration for waiting for the database server to be ready before starting the service.
    waitForServer:
      resources: {} # Resources allocated for the wait operation, usually minimal.

    # Configuration for running database migrations.
    migration:
      resources: {} # Resources allocated for migration operations, define as needed.

  # Configuration for the 'dummyData' service, used for deploying dummy data for testing purposes.
  dummyData:
    enabled: false
    registry: ""
    repository: exivity/dummy-data
    tag: "main" # Tag should be changed to match the rest in the future
    pullPolicy: ""
    nodeName: ""
    nodeSelector: {}
    resources: {}

  # Configuration for the 'edify' service, part of the backend processing components.
  edify:
    registry: ""
    repository: exivity/edify
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    # It is recommended to set tmpPath to "/tmp" to prevent temporary files from being written to the PVC, which could impact service performance.
    # tmpPath: "/tmp"  # Custom path for temporary files and caching.
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'executor' service, part of the backend processing components.
  executor:
    registry: ""
    repository: exivity/executor
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'griffon' service, part of the backend processing components.
  griffon:
    registry: ""
    repository: exivity/griffon
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'horizon' service, part of the backend processing components.
  horizon:
    registry: ""
    repository: exivity/horizon
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'pigeon' service, which serves as the notification system.
  pigeon:
    registry: ""
    repository: exivity/pigeon
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'proximityCli' service, part of the backend processing components.
  proximityCli:
    registry: ""
    repository: exivity/proximity-cli
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'transcript' service, part of the backend processing components.
  transcript:
    registry: ""
    repository: exivity/transcript
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

  # Configuration for the 'use' service, part of the backend processing components.
  use:
    registry: ""
    repository: exivity/use
    tag: ""
    pullPolicy: ""
    replicas: 1
    nodeName: ""
    nodeSelector: {}

    # Resource requirements for the service pod.
    resources:
      requests:
        cpu: "25m"
        memory: "50Mi"

    # Configuration for the init container that installs CA certificates.
    initContainers:
      installCACert:
        resources:
          requests:
            cpu: "25m"
            memory: "50Mi"

    # CA certificates configuration section. Add CA certificates that your service uses here.
    # Each certificate should be listed as a key-value pair, where the key is a unique identifier.
    caCertificates:
      # Example placeholders for CA certificates. Replace with your actual certificate data.
      # rootCA.pem:
      #   -----BEGIN CERTIFICATE-----
      #   [Your Root CA certificate here]
      #   -----END CERTIFICATE-----
      # intermediateCA.pem:
      #   -----BEGIN CERTIFICATE-----
      #   [Your Intermediate CA certificate here]
      #   -----END CERTIFICATE-----

# Default log level for backend services. Accepts 'debug', 'info'.
# Use 'debug' for development environments and 'info' or higher for production to reduce log verbosity.
logLevel:
  backend: "info"

# Configuration for readiness and liveness probes for services.
# These settings allow you to enable or disable the probes and configure their parameters.
probes:
  livenessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 30
    failureThreshold: 120
  readinessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 30
    failureThreshold: 60

# Prometheus monitoring configuration
prometheus:
  metricServer:
    enabled: false
    serviceMonitor:
      enabled: false
